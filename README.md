# AgentSwitchboard - Zero-SDK Proxy

> **Anti-Gravity**: Making agent deployment frictionless by removing the "weight" of security and cost concerns.

## ğŸš€ Quick Start

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f proxy

# Open Mission Control Dashboard
open http://localhost:3000
```

## One-Line Integration

Change your `base_url` â€” that's it:

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-key",
    base_url="http://localhost:8080/v1",  # â† One line change
    default_headers={"X-Switchboard-Token": "demo_token_abc123"}
)

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Your AI Agents                           â”‚
â”‚         (Python, TypeScript, Mojo - any framework)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 AgentSwitchboard Proxy                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Semantic   â”‚  â”‚   Traffic   â”‚  â”‚   Flight Recorder   â”‚  â”‚
â”‚  â”‚  Firewall   â”‚  â”‚  Controller â”‚  â”‚     (Traces)        â”‚  â”‚
â”‚  â”‚  (< 10ms)   â”‚  â”‚  (Locking)  â”‚  â”‚                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Upstream AI Providers                          â”‚
â”‚         (OpenAI, Anthropic, Google, Azure)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features

### ğŸ›¡ï¸ Semantic Firewall
- Real-time intent classification (< 10ms latency)
- PII detection via Bloom filters
- Dangerous pattern blocking (SQL injection, shell commands)
- Customizable policies per organization

### âœˆï¸ Flight Recorder
- Full request/response logging
- Reasoning chain capture
- Tool call tracking
- Cost calculation

### ğŸš¦ Traffic Controller
- Multi-agent conflict resolution
- Distributed locking via Redis
- Priority-based queuing

### ğŸ“Š Mission Control Dashboard
- Real-time burn rate monitoring
- Agent fleet management
- Anomaly detection
- Global kill switch

## Services

| Service | Port | Description |
|---------|------|-------------|
| `proxy` | 8080 | Main proxy service |
| `dashboard` | 3000 | Mission Control UI |
| `redis` | 6379 | Cache & locking |
| `timescaledb` | 5432 | Trace storage |

## Development

```bash
# Install dependencies
npm install

# Run proxy in dev mode
cd services/proxy && npm run dev

# Run dashboard in dev mode
cd services/dashboard && npm run dev

# Run tests
npm test
```

## Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | 8080 | Proxy port |
| `REDIS_URL` | redis://localhost:6379 | Redis connection |
| `TIMESCALE_URL` | postgres://... | TimescaleDB connection |
| `UPSTREAM_OPENAI` | https://api.openai.com | OpenAI upstream |

## API Endpoints

### Proxy (mirrors OpenAI API)
- `POST /v1/chat/completions`
- `POST /v1/embeddings`
- `GET /v1/models`

### Internal API
- `GET /api/burn-rate/:orgId`
- `GET /api/agents/:orgId`
- `GET /api/traces/:orgId`
- `POST /api/control/pause-all`
- `POST /api/control/pause-agent`
- `POST /api/control/revoke-token`

## License

MIT
